{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import auth\n",
    "import socket\n",
    "import numpy as np\n",
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "from pandas.io.json import json_normalize\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "def get_token(_auth_data, _url_token):\n",
    "    _auth_data = json.dumps(_auth_data)\n",
    "    response = requests.post(\n",
    "        _url_token,\n",
    "        data=_auth_data\n",
    "    )\n",
    "    _token = response.json()['data']['user']['data']['auth_token']\n",
    "    return _token\n",
    "\n",
    "\n",
    "def get_data(_token, _url_list):\n",
    "    _headers = {'Authorization': 'token' + ' ' + _token}\n",
    "    _r = requests.post(\n",
    "        _url_list,\n",
    "        headers=_headers\n",
    "    )\n",
    "    return _r.json()\n",
    "\n",
    "def determine_direction(x):\n",
    "    x = str(x)\n",
    "    if x == \"BTS\" or x == \"KSC\" or x == \"SLD\" or x == \"TAT\":\n",
    "        return str(\"TAM\")\n",
    "    else:\n",
    "        return str(\"SPAT\")\n",
    "\n",
    "def determine_production(x):\n",
    "    x = str(x)\n",
    "    if x == \"BTS\":\n",
    "        return str(\"BTS\")\n",
    "    elif x == \"KSC\":\n",
    "        return str(\"KSC\")\n",
    "    else:\n",
    "        return str(\"---\")\n",
    "\n",
    "def extra_catering(x):\n",
    "    try:\n",
    "        _count = x[0]['count']\n",
    "        return _count\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def extra_catering_code(x):\n",
    "    try:\n",
    "        _code = x[0]['code']\n",
    "        return _code\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def render_tables(_data):\n",
    "    _df = json_normalize(_data['data']['flight']['data'])\n",
    "    _compare = pd.DataFrame()\n",
    "\n",
    "    _compare['Departure'] = pd.to_datetime(_df['local_std_date'] + ' ' + _df['local_std_time'])\n",
    "    _compare['Depart'] = _compare['Departure']\n",
    "    _compare['Arrival'] = pd.to_datetime(_df['local_sta_date'] + ' ' + _df['local_sta_time'])\n",
    "    _compare['Flight'] = _df['flight_number']\n",
    "    _compare['Aircraft'] = _df['aircraft_config']\n",
    "    _compare['Reg'] = _df['aircraft_reg']\n",
    "    _compare[\"Meal\"] = _df[\"catering_order.flight_meal_type\"]\n",
    "    _compare['Direction'] = _df['departure_iata'].map(determine_direction)\n",
    "    _compare['Production'] = _df['departure_iata'].map(determine_production)\n",
    "    _compare['From'] = _df['departure_iata']\n",
    "    _compare['To'] = _df['destination_iata']\n",
    "    _compare['Quantity'] = _df['catering_order.quantity_y']\n",
    "    _compare['Crew'] = _df['catering_order.quantity_crew']\n",
    "    _compare['Extra Count'] = _df['extra_catering'].map(extra_catering)\n",
    "    _compare['Extra Code'] = _df['extra_catering'].map(extra_catering_code)\n",
    "    #_compare['Extra Plain'] = _df['extra_catering']\n",
    "\n",
    "    div_start = \"\"\"<div class=\"hoverable\">\"\"\"\n",
    "    div_end = \"</div>\"\n",
    "    _compare['Note'] = _df['catering_order.general_note'].map(lambda x: \"{0}{1}{2}\".format(div_start, str(x), div_end))\n",
    "    _compare['Note'] = _compare['Note'].map(lambda x: str(x).replace('\\n', \"<br>\"))\n",
    "    _compare['Note'] = _compare['Note'].map(lambda x: str(x).replace('\\r', ''))\n",
    "    # _compare = _compare.sort_values(['Departure', 'Meal'],ascending=[True, True])\n",
    "    _compare['Quantity'] = _compare['Quantity'].fillna(0)\n",
    "    _compare['Crew'] = _compare['Crew'].fillna(0)\n",
    "\n",
    "    _compare.index = _compare['Departure']\n",
    "\n",
    "    _allUniqueDays = _df['local_std_date'].unique()\n",
    "    _allUniqueDays = np.sort(_allUniqueDays)\n",
    "    _allUniqueReg = _df['aircraft_reg'].unique()\n",
    "\n",
    "    tables = {}\n",
    "    _list_view_by_dates = {}\n",
    "    for i in _allUniqueDays:\n",
    "        # split _comapre dataframe by days first\n",
    "        temp_table_day_chunck = _compare.loc[i]\n",
    "        _list_view_by_dates[i] = temp_table_day_chunck\n",
    "        # taking partuicular day and sorting it by 'aircraft_reg' and then by 'departure date'\n",
    "        # splitting particular day into unique 'aircraft_reg' - something like car plates :)\n",
    "        temp_storage = {}\n",
    "        for _reg in _allUniqueReg:\n",
    "\n",
    "            sorting_particular_day_df = temp_table_day_chunck.sort_values([\"Reg\",\"Depart\"], ascending=True)\n",
    "            try:\n",
    "                is_dataframe = sorting_particular_day_df.loc[sorting_particular_day_df['Reg'] == _reg]\n",
    "                if not is_dataframe.empty:\n",
    "                    temp_storage[_reg] = sorting_particular_day_df.loc[sorting_particular_day_df['Reg'] == _reg]\n",
    "                # data.loc[data['first_name'] == 'Antonio', 'city':'email']\n",
    "\n",
    "            except Exception as missing_reg:\n",
    "                # print('This {} for date: {} is missing.'.format(_reg, i))\n",
    "                temp_storage[_reg] = \"<empty>\"\n",
    "\n",
    "        tables[i] = temp_storage\n",
    "\n",
    "\n",
    "    # ****************************************************************\n",
    "    # _list_view_by_dates = {\"2018-06-03\": \"...\", \"2018-06-04\": \"....\", ...}\n",
    "    # ****************************************************************\n",
    "    return tables, _allUniqueDays, _compare, _df, _allUniqueReg, _list_view_by_dates\n",
    "\n",
    "\n",
    "def process_tables_to_html(_tables, _allUniqueDays, _allUniqueReg, _list_view_by_dates):\n",
    "    tables_html_aggr = {}\n",
    "    tables_html_list = {}\n",
    "    _detail_aggr = {}\n",
    "    _detail_list = {}\n",
    "\n",
    "    for k in _allUniqueDays:\n",
    "        # aggregation table - little\n",
    "        # This is Detail page for each day in the second NAVBAR\n",
    "        _detail_aggr[k] = _list_view_by_dates[k].groupby(['Meal','Direction']).sum().to_html(classes=\"table table-sm table-hover table-striped table-responsive\", escape=False)\n",
    "        # _compare = _compare.sort_values(['Departure', 'Meal'],ascending=[True, True])\n",
    "        # _detail_list[k] = _list_view_by_dates[k].sort_values(['Departure', 'Meal'],ascending=[True, True]).drop('Departure', axis=1).to_html(classes=\"table table-sm table-hover table-striped table-responsive-xl first-bold\", escape=False, index=False)\n",
    "        _detail_list[k] = _list_view_by_dates[k].sort_values(['Reg', 'Depart'],ascending=[True, True]).drop('Departure', axis=1).to_html(classes=\"table table-sm table-hover table-striped table-responsive-xl first-bold\", escape=False, index=False)\n",
    "        \n",
    "        temp_aggr_dict = {}\n",
    "        temp_list_table_dict = {}\n",
    "        for _reg in _allUniqueReg:\n",
    "            try:\n",
    "                temp_aggr = _tables[k][_reg].groupby(['Meal','Direction']).sum()\n",
    "                temp_aggr_dict[_reg] = temp_aggr.to_html(classes=\"table table-sm table-hover table-striped table-responsive\", escape=False)\n",
    "            except Exception as aggr_exists_error:\n",
    "                pass\n",
    "                # print('No such REG key: {}'.format(aggr_exists_error))\n",
    "\n",
    "            try:\n",
    "                # Remove column\n",
    "                removed_column = _tables[k][_reg].drop('Departure', axis=1)\n",
    "                # Remove empty row\n",
    "                temp_list_table_dict[_reg] = removed_column.to_html(classes=\"table table-sm table-hover table-striped table-responsive-xl first-bold\", escape=False, index=False)\n",
    "\n",
    "            except Exception as list_table_error:\n",
    "                pass\n",
    "                # print('No such REG key for list view: {}'.format(list_table_error))\n",
    "        # ******************************************\n",
    "\n",
    "\n",
    "\n",
    "        tables_html_aggr[k] = temp_aggr_dict\n",
    "        tables_html_list[k] = temp_list_table_dict\n",
    "\n",
    "    return tables_html_list, tables_html_aggr, allUniqueDays, _detail_aggr, _detail_list\n",
    "\n",
    "\n",
    "def create_files_main_dates(_tables_html_list,\n",
    "                _tables_html_aggr,\n",
    "                _allUniqueDays,\n",
    "                _path_template,\n",
    "                _day_tamplate,\n",
    "                _allUniqueReg):\n",
    "    ts = \"Last update on: {} time: {}\".format(datetime.date.today().strftime(\"%d/%B/%Y\"), time.strftime(\"%H:%M:%S\"))\n",
    "    for _day in np.sort(allUniqueDays):\n",
    "        j2_env = Environment(loader=FileSystemLoader(_path_template))\n",
    "        # unique set of REGs\n",
    "        _ureg = list(listx[_day].keys())\n",
    "        _data = j2_env.get_template(_day_tamplate).render(particular_day_content_list=_tables_html_list[_day],\n",
    "                                                          particular_day_content_aggr=_tables_html_aggr[_day],\n",
    "                                                          unique_reg=_ureg,\n",
    "                                                          xday=_day,\n",
    "                                                          timeStamp=ts)\n",
    "\n",
    "        _filename = str(_day + \".html\")\n",
    "        if socket.gethostname() != \"nb-toth\":\n",
    "            _serve = 'twowings'\n",
    "            _oname = os.path.join(_path_template, _serve, _filename)\n",
    "        else:\n",
    "            _oname = os.path.join(_path_template, _filename)\n",
    "        with open(_oname, 'w') as f:\n",
    "            f.write(_data)\n",
    "\n",
    "def create_files_reg(_tables_html_list,\n",
    "                     _tables_html_aggr,\n",
    "                     _allUniqueDays,\n",
    "                     _path_template,\n",
    "                     _reg_tamplate,\n",
    "                     _allUniqueReg,\n",
    "                     _detail_aggr,\n",
    "                     _detail_list,\n",
    "                     _detail_list_view,\n",
    "                     _list_view_by_dates):\n",
    "    ts = \"Last update on: {} time: {}\".format(datetime.date.today().strftime(\"%d/%B/%Y\"), time.strftime(\"%H:%M:%S\"))\n",
    "    for _day in np.sort(allUniqueDays):\n",
    "        j2_env = Environment(loader=FileSystemLoader(_path_template))\n",
    "\n",
    "        # ************************************************************\n",
    "        _detail_filename = str(\"detail\" + \"-\"+ _day + \".html\")\n",
    "        \n",
    "        zerox = ['0.0']\n",
    "        tmpx = pd.DataFrame(_list_view_by_dates[_day]) \n",
    "        tmpx = tmpx[~tmpx.Quantity.isin(zerox)]\n",
    "        tmpx = pd.DataFrame(tmpx.groupby(['Meal','Direction']).count().iloc[:,1])\n",
    "        _special_quantity = {k:[v, int(v)*189] for k,v in tmpx.to_dict()['Depart'].items()}\n",
    "        \n",
    "        # _special_quantity = pd.DataFrame(_list_view_by_dates[_day].groupby(['Meal','Direction']).count().iloc[:,1])  \n",
    "        # _special_quantity = {k[0]:[v, int(v)*189] for k,v in _special_quantity.to_dict()['Depart'].items() if k[1] == \"TAM\"}\n",
    "        # print('_special_quantity:{} -> {}'.format(_day, _special_quantity))\n",
    "        \n",
    "        \n",
    "        # Example output:\n",
    "        # _special_quantity ----> {'Count': {'L2': 8, 'L6': 7, 'RRR': 2},'Quantity189': {'L2': 1512, 'L6': 1323, 'RRR': 378}}\n",
    "        \n",
    "        _detail_data = j2_env.get_template(_detail_list_view).render(detail_day_content_aggr=_detail_aggr[_day],\n",
    "                                                                     detail_day_content_list=_detail_list[_day],\n",
    "                                                                     detail_day=_day,\n",
    "                                                                     special_quantity = _special_quantity\n",
    "                                                                     )\n",
    "\n",
    "        if socket.gethostname() != \"nb-toth\":\n",
    "            _serve = 'twowings'\n",
    "            _oname = os.path.join(_path_template, _serve, _detail_filename)\n",
    "        else:\n",
    "            _oname = os.path.join(_path_template, _detail_filename)\n",
    "        with open(_oname, 'w') as f:\n",
    "            f.write(_detail_data)\n",
    "        # ************************************************************\n",
    "\n",
    "        for _r in _allUniqueReg:\n",
    "            try:\n",
    "                _filename = str(_r + \"-\"+ _day + \".html\")\n",
    "                _data = j2_env.get_template(_reg_tamplate).render(particular_day_content_list=_tables_html_list[_day][_r],\n",
    "                                                                  particular_day_content_aggr=_tables_html_aggr[_day][_r],\n",
    "                                                                  unique_reg=_allUniqueReg,\n",
    "                                                                  xday=_day,\n",
    "                                                                  timeStamp=ts,\n",
    "                                                                  reg_key=_r)\n",
    "\n",
    "                # {{ _reg }}-{{ xday }}\n",
    "                if socket.gethostname() != \"nb-toth\":\n",
    "                    _serve = 'twowings'\n",
    "                    _oname = os.path.join(_path_template, _serve, _filename)\n",
    "                else:\n",
    "                    _oname = os.path.join(_path_template, _filename)\n",
    "                with open(_oname, 'w') as f:\n",
    "                    f.write(_data)\n",
    "\n",
    "            except Exception as missing_key:\n",
    "                #print('Missing key: {}, I am not going to create this file: {}'.format(missing_key, _filename))\n",
    "                pass\n",
    "\n",
    "\n",
    "def create_main(_path_template,\n",
    "                _main_tamplate,\n",
    "                _unique_days):\n",
    "\n",
    "    ts = \"Last update on: {} time: {}\".format(datetime.date.today().strftime(\"%d/%B/%Y\"), time.strftime(\"%H:%M:%S\"))\n",
    "    j2_env = Environment(loader=FileSystemLoader(_path_template))\n",
    "    _data = j2_env.get_template(_main_tamplate).render(unique_days=_unique_days, timeStamp=ts)\n",
    "    _filename = str(\"index.html\")\n",
    "    if socket.gethostname() != \"nb-toth\":\n",
    "        _serve = 'twowings'\n",
    "        _omain = os.path.join(_path_template, _serve, _filename)\n",
    "    else:\n",
    "        _omain = os.path.join(_path_template, _filename)\n",
    "        # print('saving to {}'.format(_omain))\n",
    "    with open(_omain, 'w') as f:\n",
    "        f.write(_data)\n",
    "\n",
    "\n",
    "def get_cred():\n",
    "    password = auth.login['password']\n",
    "    username = auth.login['username']\n",
    "    url_token = auth.login['url_token']\n",
    "    url_list = auth.login['url_list']\n",
    "\n",
    "    auth_data = {\n",
    "        'auth_company': 'TVS',\n",
    "        'auth_username': username,\n",
    "        'auth_password': password\n",
    "    }\n",
    "    return auth_data, url_token, url_list\n",
    "\n",
    "\n",
    "path_template = \"C:\\\\Users\\\\jan.toth\\\\Documents\\\\2w\"\n",
    "linux_template = \"/opt/twowings\"\n",
    "day_tamplate = \"particular_day_navbar.tpl\"\n",
    "reg_template = \"particular_day.tpl\"\n",
    "detail_list_view = \"detail_list_view.tpl\"\n",
    "\n",
    "main_template = \"main.tpl\"\n",
    "sleep_period = 300\n",
    "\n",
    "if socket.gethostname() != \"nb-toth\":\n",
    "    while True:\n",
    "        try:\n",
    "            auth_data, url_token, url_list = get_cred()\n",
    "            token = get_token(auth_data, url_token)\n",
    "            render = get_data(token, url_list)\n",
    "            tables, allUniqueDays, dataframe, plain, allUniqueReg, list_view_by_dates = render_tables(render)\n",
    "            listx, aggrx, udays, detail_aggr, detail_list = process_tables_to_html(tables, allUniqueDays, allUniqueReg, list_view_by_dates)\n",
    "            create_files_main_dates(listx, aggrx, udays, linux_template, day_tamplate, allUniqueReg)\n",
    "            create_files_reg(listx, aggrx, udays, linux_template, reg_template, allUniqueReg, detail_aggr, detail_list, detail_list_view, list_view_by_dates)\n",
    "            create_main(linux_template, main_template, udays)\n",
    "            time.sleep(sleep_period)\n",
    "        except Exception as e:\n",
    "            with open('error_log.txt', 'a') as f:\n",
    "                tstr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "                f.write('{}: {}\\n'.format(tstr, e))\n",
    "            time.sleep(sleep_period)\n",
    "\n",
    "\n",
    "if socket.gethostname() == \"nb-toth\":\n",
    "    auth_data, url_token, url_list = get_cred()\n",
    "    token = get_token(auth_data, url_token)\n",
    "    render = get_data(token, url_list)\n",
    "    tables, allUniqueDays, dataframe, plain, allUniqueReg, list_view_by_dates = render_tables(render)\n",
    "    listx, aggrx, udays, detail_aggr, detail_list = process_tables_to_html(tables, allUniqueDays, allUniqueReg, list_view_by_dates)\n",
    "    create_files_main_dates(listx, aggrx, udays, path_template, day_tamplate, allUniqueReg)\n",
    "    create_files_reg(listx, aggrx, udays, path_template, reg_template, allUniqueReg, detail_aggr, detail_list, detail_list_view, list_view_by_dates)\n",
    "    create_main(path_template, main_template, udays)\n",
    "    print(\"Done!\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L2   SPAT': [1, 189],\n",
       " 'L2   TAM': [4, 756],\n",
       " 'L6   SPAT': [2, 378],\n",
       " 'L6   TAM': [3, 567]}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zerox = ['0.0']\n",
    "tmpx = pd.DataFrame(list_view_by_dates['2018-06-14']) \n",
    "tmpx = tmpx[~tmpx.Quantity.isin(zerox)]\n",
    "\n",
    "tmpx = pd.DataFrame(tmpx.groupby(['Meal','Direction']).count().iloc[:,1])\n",
    "tmpx.to_dict()\n",
    "{'{:<5}{}'.format(k[0], k[1]):[v, int(v)*189] for k,v in tmpx.to_dict()['Depart'].items()}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
