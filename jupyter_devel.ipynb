{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from flask import Flask\n",
    "import json\n",
    "import time\n",
    "import auth\n",
    "import pytz\n",
    "import uuid\n",
    "import hashlib\n",
    "import socket\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "from pandas.io.json import json_normalize\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "colors = [\n",
    "    'red',\n",
    "    'black',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'cyan',\n",
    "    'pink',\n",
    "    'orange',\n",
    "    'green',\n",
    "    'brown',\n",
    "    'grey',\n",
    "    'red',\n",
    "    'black',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'cyan',\n",
    "    'pink',\n",
    "    'orange',\n",
    "    'green',\n",
    "    'brown',\n",
    "    'grey',\n",
    "    'red',\n",
    "    'black',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'cyan',\n",
    "    'pink',\n",
    "    'orange',\n",
    "    'green',\n",
    "    'brown',\n",
    "    'grey',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'cyan',\n",
    "    'pink',\n",
    "    'orange',\n",
    "    'green',\n",
    "    'brown',\n",
    "    'grey',\n",
    "    'red',\n",
    "    'black',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'cyan',\n",
    "    'pink',\n",
    "    'orange',\n",
    "    'green',\n",
    "    'brown',\n",
    "    'grey',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'cyan',\n",
    "    'pink',\n",
    "    'orange',\n",
    "    'green',\n",
    "    'brown',\n",
    "    'grey',\n",
    "    'red',\n",
    "    'black',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'cyan',\n",
    "    'pink',\n",
    "    'orange',\n",
    "    'green',\n",
    "    'brown',\n",
    "    'grey',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'cyan',\n",
    "    'pink',\n",
    "    'orange',\n",
    "    'green',\n",
    "    'brown',\n",
    "    'grey',\n",
    "    'red',\n",
    "    'black',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'cyan',\n",
    "    'pink',\n",
    "    'orange',\n",
    "    'green',\n",
    "    'brown',\n",
    "    'grey',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'cyan',\n",
    "    'pink',\n",
    "    'orange',\n",
    "    'green',\n",
    "    'brown',\n",
    "    'grey',\n",
    "    'red',\n",
    "    'black',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'cyan',\n",
    "    'pink',\n",
    "    'orange',\n",
    "    'green',\n",
    "    'brown',\n",
    "    'grey',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'cyan',\n",
    "    'pink',\n",
    "    'orange',\n",
    "    'green',\n",
    "    'brown',\n",
    "    'grey',\n",
    "    'red',\n",
    "    'black',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'cyan',\n",
    "    'pink',\n",
    "    'orange',\n",
    "    'green',\n",
    "    'brown',\n",
    "    'grey',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'cyan',\n",
    "    'pink',\n",
    "    'orange',\n",
    "    'green',\n",
    "    'brown',\n",
    "    'grey',\n",
    "    'red',\n",
    "    'black',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'cyan',\n",
    "    'pink',\n",
    "    'orange',\n",
    "    'green',\n",
    "    'brown',\n",
    "    'grey',\n",
    "]\n",
    "\n",
    "def get_datax(_db):\n",
    "    conn = sqlite3.connect(_db)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT json_data FROM flight_data ORDER BY created DESC LIMIT 1\")\n",
    "    _data = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return _data\n",
    "\n",
    "def determine_direction(x):\n",
    "    \"\"\"\n",
    "\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = str(x)\n",
    "    if x == \"BTS\" or x == \"KSC\" or x == \"SLD\" or x == \"TAT\":\n",
    "        return str(\"TAM\")\n",
    "    else:\n",
    "        return str(\"SPAT\")\n",
    "\n",
    "\n",
    "def determine_production(x):\n",
    "    \"\"\"\n",
    "\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = str(x)\n",
    "    if x == \"BTS\":\n",
    "        return str(\"BTS\")\n",
    "    elif x == \"KSC\":\n",
    "        return str(\"KSC\")\n",
    "    else:\n",
    "        return str(\"---\")\n",
    "\n",
    "\n",
    "def extra_catering(x):\n",
    "    \"\"\"\n",
    "\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return ['{0}: {1}'.format(i['code'],i['count']) for i in x]\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# def split_data_at_time(_df, _time):\n",
    "#     a = _df.loc[_time:, :]\n",
    "#     delimiter = a.iloc[:1].index.values[0]\n",
    "#     b = _df.loc[:delimiter, :]\n",
    "#     b = b.drop(delimiter)\n",
    "#     return a, b, delimiter\n",
    "\n",
    "\n",
    "def split_data_at_time(_df, _time):\n",
    "    if 'xUID' not in _df:                                # temporarily create unique index, if does not exists\n",
    "        _df['xUID'] = range(_df.shape[0])\n",
    "    a = _df.loc[_time:, :]\n",
    "    delimiter = a.iloc[:1].index.values[0]\n",
    "    delimiter = _df[_df.index == delimiter].ix[0].xUID   # get unique index of first occurrence of delimiter\n",
    "    b = _df[_df['xUID'] < delimiter]                     # split data-frame based on new index\n",
    "    del _df['xUID']                                      # drop index since it's not needed anymore\n",
    "    return a, b, delimiter\n",
    "\n",
    "\n",
    "\n",
    "def get_unique_routes(_df):\n",
    "    return set(_df['Route'].unique().tolist())\n",
    "\n",
    "\n",
    "\n",
    "def get_unique_days(_data):\n",
    "    \"\"\"\n",
    "    :param _data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    _raw_data = json.loads((_data[0][0]).decode(\"utf-8\"))\n",
    "    _df = json_normalize(_raw_data['data']['flight']['data'])\n",
    "    \n",
    "    # _df = json_normalize(_data['data']['flight']['data'])\n",
    "    _df_normalized = _df\n",
    "    \n",
    "    grouped = _df.groupby(['local_std_date'])\n",
    "    _all_unique_days = []\n",
    "    for day, group in grouped:\n",
    "        minimum = group['local_std_time'].min()\n",
    "        maximum = group['local_std_time'].max()\n",
    "        _all_unique_days.append((day, minimum, maximum))\n",
    "\n",
    "    start, end = _all_unique_days[::len(_all_unique_days) - 1]\n",
    "    start = list(start[:2])\n",
    "    end = list(end[::len(end) - 1])\n",
    "    start = datetime.datetime.strptime(start[0] + ' ' + start[1], '%Y-%m-%d %H:%M:%S')\n",
    "    end = datetime.datetime.strptime(end[0] + ' ' + end[1], '%Y-%m-%d %H:%M:%S')\n",
    "    final = []\n",
    "    a = start\n",
    "    while True:\n",
    "        b = (a + datetime.timedelta(1)).replace(hour=9, minute=0)\n",
    "        if b > end:\n",
    "            b = end\n",
    "            final.append('{}___{}'.format(str(a), str(b)))\n",
    "            break\n",
    "        final.append('{}___{}'.format(str(a), str(b)))\n",
    "        a = b\n",
    "    return final, _df\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "def hash_column(_string):\n",
    "    # uuid is used to generate a random number\n",
    "    salt = uuid.uuid4().hex\n",
    "    return hashlib.sha256(salt.encode() + _string.encode()).hexdigest() + ':' + salt\n",
    "\n",
    "def undo_hash(hashed_password, user_password):\n",
    "    password, salt = hashed_password.split(':')\n",
    "    return password == hashlib.sha256(salt.encode() + user_password.encode()).hexdigest()\n",
    "\n",
    "\n",
    "def render_tables(_df_normalized):\n",
    "    \"\"\"\n",
    "\n",
    "    :param _df_normalized:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    _df = _df_normalized\n",
    "    _compare = pd.DataFrame()\n",
    "    unique = _df['route_id'].unique().tolist()\n",
    "    color_map = {str(u): c for u, c in zip(unique, colors)}\n",
    "\n",
    "    _compare['Departure'] = pd.to_datetime(_df['local_std_date'] + ' ' + _df['local_std_time'])\n",
    "    _compare['Depart'] = _compare['Departure']\n",
    "    _compare[''] = _df['route_id'].map(\n",
    "        lambda x: '<span style=\"border-left: 12px solid {0};\"></span>'.format(color_map[str(x)]))\n",
    "    _compare['Arrival'] = pd.to_datetime(_df['local_sta_date'] + ' ' + _df['local_sta_time'])\n",
    "    _compare['Flight'] = _df['flight_number']\n",
    "    _compare['Aircraft'] = _df['aircraft_config']\n",
    "    _compare['Hash'] = _df['aircraft_reg'].astype(str)  + _df['route_id'].astype(str)  + _compare['Departure'].astype(str) \n",
    "    _compare['Hash'] = _compare['Hash'].map(hash_column)\n",
    "    _compare['Reg'] = _df['aircraft_reg']\n",
    "    _compare['Route'] = _df['route_id']\n",
    "    _compare[\"Meal\"] = _df[\"catering_order.flight_meal_type\"]\n",
    "    _compare['Direction'] = _df['departure_iata'].map(determine_direction)\n",
    "    _compare['Production'] = _df['departure_iata'].map(determine_production)\n",
    "    _compare['From'] = _df['departure_iata']\n",
    "    _compare['To'] = _df['destination_iata']\n",
    "\n",
    "    _compare['Quantity'] = _df['catering_order.quantity_y']\n",
    "    _compare['Crew'] = _df['catering_order.quantity_crew']\n",
    "    _compare['Extra Catering'] = _df['extra_catering'].map(extra_catering)\n",
    "    _compare['Note'] = _df['catering_order.general_note'].map(\n",
    "        lambda x: \"{0}{1}{2}\".format(\"\"\"<div class=\"hoverable\">\"\"\", str(x), \"</div>\"))\n",
    "    _compare['Note'] = _compare['Note'].map(lambda x: str(x).replace('\\n', \"<br>\"))\n",
    "    _compare['Note'] = _compare['Note'].map(lambda x: str(x).replace('\\r', ''))\n",
    "    _compare['Quantity'] = _compare['Quantity'].fillna(0)\n",
    "    _compare['Crew'] = _compare['Crew'].fillna(0)\n",
    "    _compare.index = _compare['Departure']\n",
    "    return _compare\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def select_scoped_timeframe(_compare, _all_unique_days, _day):\n",
    "    _day_dict_lookup = {i.replace(' ', '_').replace(':', '_'): i for i in _all_unique_days}\n",
    "    DAY = _day_dict_lookup[_day]\n",
    "    FT, ST = DAY.split('___')\n",
    "    valid, invalid, dm1 = split_data_at_time(_compare, FT)\n",
    "    extra, main, dm2 = split_data_at_time(valid, ST)\n",
    "    valid_rids = get_unique_routes(valid)\n",
    "    invalid_rids = get_unique_routes(invalid)\n",
    "    intersection = invalid_rids & valid_rids\n",
    "    main_rids = get_unique_routes(main)\n",
    "    main_rids = main_rids - intersection\n",
    "    final = valid[valid['Route'].isin(list(main_rids))]\n",
    "    return final\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"2w.sqlite\"\n",
    "data = get_datax(db)\n",
    "ud, normal = get_unique_days(data)\n",
    "compare = render_tables(normal)\n",
    "compare = compare.sort_values(['Depart'], ascending=[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018-07-25 02:40:00___2018-07-26 09:00:00',\n",
       " '2018-07-26 09:00:00___2018-07-27 09:00:00',\n",
       " '2018-07-27 09:00:00___2018-07-28 09:00:00',\n",
       " '2018-07-28 09:00:00___2018-07-29 00:35:00']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {i.replace(' ', '_').replace(':', '_'): i for i in ud}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:225: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "sliced = []\n",
    "for i in x.keys():\n",
    "    sliced.append(select_scoped_timeframe(compare, ud, i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = []\n",
    "for i in sliced:\n",
    "    hashes.append(set(i['Hash'].unique().tolist())) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashes[0] & hashes[1]\n",
    "hashes[1] & hashes[2]\n",
    "hashes[2] & hashes[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164, 18)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(sliced).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " \n",
    "def hash_column(_string):\n",
    "    # uuid is used to generate a random number\n",
    "    salt = uuid.uuid4().hex\n",
    "    return hashlib.sha256(salt.encode() + _string.encode()).hexdigest() + ':' + salt\n",
    "\n",
    "def undo_hash(hashed_password, user_password):\n",
    "    password, salt = hashed_password.split(':')\n",
    "    return password == hashlib.sha256(salt.encode() + user_password.encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = hash_column('jahoda')\n",
    "b = hash_column('jablko')\n",
    "\n",
    "check_password(a, b)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
